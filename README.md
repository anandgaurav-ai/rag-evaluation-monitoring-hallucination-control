ğŸ§  RAG Evaluation, Monitoring & Hallucination Control System

This repository demonstrates a production-grade Retrieval-Augmented Generation (RAG) system with a strong focus on:

ğŸ” Retrieval evaluation

ğŸš« Hallucination detection

ğŸ“Š Confidence-based decision making

ğŸ“ Monitoring & observability

Unlike typical RAG demos, this system does not always answer.
It explicitly refuses when confidence is low.

ğŸš€ Key Features

FAISS-based retrieval with SentenceTransformers

Strictly grounded answer generation

Rule-based + LLM-based faithfulness checks

Confidence scoring combining retrieval & faithfulness

Decision controller (answer vs refuse)

Structured JSON logging for monitoring

Offline retrieval evaluation (Recall@K)

ğŸ—ï¸ Architecture Overview
Online (Inference / API)
User Query
   â†“
Retriever (FAISS)
   â†“
Context-only Generator
   â†“
Faithfulness Checks
   â†“
Confidence Scoring
   â†“
Decision (Answer / Refuse)
   â†“
Monitoring Logs

Offline (Evaluation)
eval_queries.jsonl
   â†“
Retriever
   â†“
Recall@K (R@1, R@3, R@5)


Important:
Offline evaluation and online inference are intentionally separated.

ğŸ§  Design Philosophy

Never hallucinate confidently

Prefer refusal over misinformation

Separate evaluation from inference

Keep signals explainable

Optimize for production realism

